{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "y1-bVkYqpi1G"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Environment accordingly\n",
    "os.environ['JAVA_HOME'] = \"/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/\"\n",
    "os.environ['SPARK_HOME'] = \"/Users/simran/Downloads/spark-3.5.5-bin-hadoop3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"./data/full_history\"\n",
    "file_pattern = \"*.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BigDataProject1\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.executor.memory\", \"12g\") \\\n",
    "    .config(\"spark.driver.memory\", \"15g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", True) \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"20g\") \\\n",
    "    .config(\"spark.default.parallelism\", \"100\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.JavaSerializer\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, DateType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"date\", DateType(), True),\n",
    "    StructField(\"volume\", DoubleType(), True),  \n",
    "    StructField(\"open\", DoubleType(), True),\n",
    "    StructField(\"high\", DoubleType(), True),\n",
    "    StructField(\"low\", DoubleType(), True),\n",
    "    StructField(\"close\", DoubleType(), True),\n",
    "    StructField(\"adj close\", DoubleType(), True),\n",
    "    StructField(\"StockName\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-----------------+------------------+------------------+------------------+------------------+---------+\n",
      "|      date| volume|             open|              high|               low|             close|         adj close|StockName|\n",
      "+----------+-------+-----------------+------------------+------------------+------------------+------------------+---------+\n",
      "|2023-12-28|5703600|30.14999961853028|30.239999771118164|29.950000762939453| 30.18000030517578| 30.18000030517578|      HPQ|\n",
      "|2023-12-27|5127900|30.39999961853028|30.520000457763672|30.209999084472656|30.239999771118164|30.239999771118164|      HPQ|\n",
      "|2023-12-26|4853600|30.13999938964844|30.549999237060547|30.059999465942383| 30.40999984741211| 30.40999984741211|      HPQ|\n",
      "|2023-12-22|4476400|30.21999931335449|30.479999542236328| 30.06999969482422| 30.18000030517578| 30.18000030517578|      HPQ|\n",
      "|2023-12-21|6529200|30.07999992370605| 30.21999931335449| 29.90999984741211| 30.13999938964844| 30.13999938964844|      HPQ|\n",
      "+----------+-------+-----------------+------------------+------------------+------------------+------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load datasets as DataFrames\n",
    "history_df = spark.read.format(\"csv\") \\\n",
    "     .option(\"header\", \"true\") \\\n",
    "     .option(\"treatEmptyValuesAsNulls\", \"true\") \\\n",
    "     .option(\"schema\",schema) \\\n",
    "     .load(f\"{directory_path}/{file_pattern}\")\n",
    "\n",
    "\n",
    "history_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[date: string, volume: string, open: string, high: string, low: string, close: string, adj close: string, StockName: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "history_df = history_df.dropDuplicates()\n",
    "\n",
    "# Handle missing values for both open and close simultaneously\n",
    "history_df = history_df.na.fill({\n",
    "    \"open\": np.nan,\n",
    "    \"close\": np.nan\n",
    "})\n",
    "history_df = history_df.replace(float('nan'), None)\n",
    "\n",
    "history_df.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/26 15:15:46 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 4:=>                                                       (8 + 8) / 260]\r"
     ]
    }
   ],
   "source": [
    "history_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29677722"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Data to Pandas DataFrame to plot visualisations\n",
    "\n",
    "all_files = glob.glob(\"./data/full_history/*.csv\")\n",
    "\n",
    "history_df_pd = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "MOcxRdcQOZdN"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32d250729f7416a808170c1aaa74dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='StockNames:', options=('RIV', 'ANTE', 'CSCO', 'PRI', 'NZF', 'HLNE', 'HUBS', 'GPL', 'PSM'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c79ff08e0c43b6811d60e85ca045d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data Visualisations\n",
    "\n",
    "#Time series visualisation given stock name\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.dates as mdate\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# Create the dropdown widget\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=sorted(list(history_df_pd['StockName'].unique())),\n",
    "    description='StockNames:'\n",
    ")\n",
    "\n",
    "# Function to update the plot based on dropdown selection\n",
    "def update_plot(category):\n",
    "    plt.clf() # Clear previous plot\n",
    "    filtered_df = history_df_pd[history_df_pd['StockName'] == category]\n",
    "    filtered_df.loc[:,'date'] = pd.to_datetime(filtered_df['date'])\n",
    "    # Plotting closing prices for a single stock\n",
    "    sorted_filtered_df = filtered_df.sort_values(by='date')\n",
    "    plt.plot(sorted_filtered_df['date'], sorted_filtered_df['close'])\n",
    "    plt.title(f'Plot for {category}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price')\n",
    "    locator = mdate.YearLocator()\n",
    "    plt.gca().xaxis.set_major_locator(locator)\n",
    "\n",
    "    plt.gcf().autofmt_xdate()\n",
    "\n",
    "\n",
    "# Observe the dropdown value and update the plot\n",
    "out = widgets.interactive_output(update_plot, {'category': dropdown})\n",
    "\n",
    "# Display the dropdown and the initial plot\n",
    "\n",
    "display(dropdown, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bb9a357042433da6cced4535b6df68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='StockNames:', options=('RIV', 'ANTE', 'CSCO', 'PRI', 'NZF', 'HLNE', 'HUBS', 'GPL', 'PSM'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545874c8ff8d4669ba0586b529d3f8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data Visualisations\n",
    "\n",
    "#Moving Averages visualisation given stock name\n",
    "\n",
    "\n",
    "# Create the dropdown widget\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=sorted(list(history_df_pd['StockName'].unique())),\n",
    "    description='StockNames:'\n",
    ")\n",
    "\n",
    "# Function to update the plot based on dropdown selection\n",
    "def update_plot(category):\n",
    "    plt.clf() # Clear previous plot\n",
    "    filtered_df = history_df_pd[history_df_pd['StockName'] == category]\n",
    "    filtered_df.loc[:,'date'] = pd.to_datetime(filtered_df['date'])\n",
    "    # Plotting closing prices for a single stock\n",
    "    sorted_filtered_df = filtered_df.sort_values(by='date')\n",
    "    ma100 = sorted_filtered_df.close.rolling(100).mean()\n",
    "    plt.plot(sorted_filtered_df['date'], sorted_filtered_df['close'])\n",
    "    plt.plot(sorted_filtered_df['date'],ma100, 'r')\n",
    "    plt.title(f'Plot for {category}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price')\n",
    "    locator = mdate.YearLocator()\n",
    "    plt.gca().xaxis.set_major_locator(locator)\n",
    "\n",
    "    plt.gcf().autofmt_xdate()\n",
    "\n",
    "\n",
    "# Observe the dropdown value and update the plot\n",
    "out = widgets.interactive_output(update_plot, {'category': dropdown})\n",
    "\n",
    "# Display the dropdown and the initial plot\n",
    "\n",
    "display(dropdown, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = history_df_pd[['open', 'high', 'low', 'close', 'adj close', 'volume']].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap of Stock Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daily Returns Distribution\n",
    "\n",
    "stock = 'AAPL'  # Replace with desired stock\n",
    "df = history_df_pd[history_df_pd['StockName'] == stock].copy()\n",
    "df = df.sort_values(by='date')\n",
    "df['daily_return'] = df['close'].pct_change()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['daily_return'].dropna(), bins=100, kde=True, color='blue')\n",
    "plt.title(f\"Daily Return Distribution for {stock}\")\n",
    "plt.xlabel(\"Daily Return\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplots for Outlier Detection\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=history_df_pd[['open', 'high', 'low', 'close', 'adj close', 'volume']])\n",
    "plt.title(\"Boxplot of Stock Features\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 Most Volatile Stocks in the Model\n",
    "df = history_df_pd.copy()\n",
    "df['daily_return'] = df.groupby('StockName')['close'].pct_change()\n",
    "volatility = df.groupby('StockName')['daily_return'].std().sort_values(ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "volatility.plot(kind='bar', color='crimson')\n",
    "plt.title(\"Top 10 Most Volatile Stocks (Std Dev of Daily Returns)\")\n",
    "plt.ylabel(\"Volatility\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

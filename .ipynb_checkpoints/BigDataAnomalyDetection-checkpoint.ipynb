{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Environment accordingly\n",
    "os.environ['JAVA_HOME'] = \"/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/\"\n",
    "os.environ['SPARK_HOME'] = \"/Users/simran/Downloads/spark-3.5.5-bin-hadoop3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"./data/full_history\"\n",
    "file_pattern = \"*.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Data to Pandas DataFrame to plot visualisations\n",
    "\n",
    "all_files = glob.glob(\"./data/full_history/*.csv\")\n",
    "\n",
    "history_df_pd = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df_pd['Date'] = pd.to_datetime(history_df_pd['date'])\n",
    "\n",
    "# set the 'Date' column as the index of the dataframe\n",
    "history_df_pd.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute Z-Score for Anomaly Detection\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def detect_anomalies(df, column):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # calculate Z-scores and add them as a new column\n",
    "    df_copy['Z-score'] = zscore(df_copy[column])\n",
    "\n",
    "    # find where the absolute Z-score is greater than 2 (common threshold for anomalies)\n",
    "    anomalies = df_copy[abs(df_copy['Z-score']) > 2]\n",
    "    return anomalies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44dffb5f3ade4289a994df8488009deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='StockNames:', options=('A', 'AA', 'AAAU', 'AACG', 'AADR', 'AAL', 'AAMC', 'AAME', 'AAN', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b8fd2c225a4c19a843f19f88d5170a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data Visualisations\n",
    "\n",
    "#Anomaly Visualisation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.dates as mdate\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# Create the dropdown widget\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=sorted(list(history_df_pd['StockName'].unique())),\n",
    "    description='StockNames:'\n",
    ")\n",
    "\n",
    "# Function to update the plot based on dropdown selection\n",
    "def update_plot(category):\n",
    "    plt.clf() # Clear previous plot\n",
    "    filtered_df = history_df_pd[history_df_pd['StockName'] == category]\n",
    "    #filtered_df.loc[:,'date'] = pd.to_datetime(filtered_df['date'])\n",
    "\n",
    "\n",
    "    sorted_filtered_df = filtered_df.sort_values(by='date')\n",
    "    adj_close_anomalies = detect_anomalies(sorted_filtered_df, 'adj close')\n",
    "    volume_anomalies = detect_anomalies(sorted_filtered_df, 'volume')\n",
    "    # Plotting closing prices for a single stock\n",
    "    _, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12))\n",
    "\n",
    "    ax1.plot(sorted_filtered_df.index, sorted_filtered_df['adj close'], label='adj close', color='blue')\n",
    "    ax1.scatter(adj_close_anomalies.index, adj_close_anomalies['adj close'], color='red', label='Anomalies')\n",
    "    ax1.set_title(f'{category} Adjusted Close Price and Anomalies')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Adjusted Close Price')\n",
    "    ax1.legend()\n",
    "\n",
    "    # volume\n",
    "    ax2.plot(sorted_filtered_df.index, sorted_filtered_df['volume'], label='volume', color='green')\n",
    "    ax2.scatter(volume_anomalies.index, volume_anomalies['volume'], color='orange', label='Anomalies')\n",
    "    ax2.set_title(f'{category} Trading Volume and Anomalies')\n",
    "    ax2.set_xlabel('Date')\n",
    "    ax2.set_ylabel('Volume')\n",
    "    ax2.legend()\n",
    "\n",
    "    locator = mdate.YearLocator()\n",
    "    plt.gca().xaxis.set_major_locator(locator)\n",
    "\n",
    "    plt.gcf().autofmt_xdate()\n",
    "\n",
    "\n",
    "# Observe the dropdown value and update the plot\n",
    "out = widgets.interactive_output(update_plot, {'category': dropdown})\n",
    "\n",
    "# Display the dropdown and the initial plot\n",
    "\n",
    "display(dropdown, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
